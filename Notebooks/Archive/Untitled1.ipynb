{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24be83a9-dd70-4d58-8eec-52d018811ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Feature Names:\n",
      "['num__temp' 'num__rain_1h' 'num__snow_1h' 'num__clouds_all' 'num__year'\n",
      " 'num__month' 'num__day' 'num__hour' 'cat__weather_main_Clear'\n",
      " 'cat__weather_main_Clouds' 'cat__weather_main_Drizzle'\n",
      " 'cat__weather_main_Fog' 'cat__weather_main_Haze' 'cat__weather_main_Mist'\n",
      " 'cat__weather_main_Rain' 'cat__weather_main_Smoke'\n",
      " 'cat__weather_main_Snow' 'cat__weather_main_Squall'\n",
      " 'cat__weather_main_Thunderstorm' 'cat__weather_description_SQUALLS'\n",
      " 'cat__weather_description_Sky is Clear'\n",
      " 'cat__weather_description_broken clouds'\n",
      " 'cat__weather_description_drizzle' 'cat__weather_description_few clouds'\n",
      " 'cat__weather_description_fog' 'cat__weather_description_freezing rain'\n",
      " 'cat__weather_description_haze'\n",
      " 'cat__weather_description_heavy intensity drizzle'\n",
      " 'cat__weather_description_heavy intensity rain'\n",
      " 'cat__weather_description_heavy snow'\n",
      " 'cat__weather_description_light intensity drizzle'\n",
      " 'cat__weather_description_light intensity shower rain'\n",
      " 'cat__weather_description_light rain'\n",
      " 'cat__weather_description_light rain and snow'\n",
      " 'cat__weather_description_light shower snow'\n",
      " 'cat__weather_description_light snow' 'cat__weather_description_mist'\n",
      " 'cat__weather_description_moderate rain'\n",
      " 'cat__weather_description_overcast clouds'\n",
      " 'cat__weather_description_proximity shower rain'\n",
      " 'cat__weather_description_proximity thunderstorm'\n",
      " 'cat__weather_description_proximity thunderstorm with drizzle'\n",
      " 'cat__weather_description_proximity thunderstorm with rain'\n",
      " 'cat__weather_description_scattered clouds'\n",
      " 'cat__weather_description_shower drizzle'\n",
      " 'cat__weather_description_shower snow'\n",
      " 'cat__weather_description_sky is clear' 'cat__weather_description_sleet'\n",
      " 'cat__weather_description_smoke' 'cat__weather_description_snow'\n",
      " 'cat__weather_description_thunderstorm'\n",
      " 'cat__weather_description_thunderstorm with drizzle'\n",
      " 'cat__weather_description_thunderstorm with heavy rain'\n",
      " 'cat__weather_description_thunderstorm with light drizzle'\n",
      " 'cat__weather_description_thunderstorm with light rain'\n",
      " 'cat__weather_description_thunderstorm with rain'\n",
      " 'cat__weather_description_very heavy rain' 'holiday__holiday_binary']\n",
      "\n",
      "Transformed data shape: (28922, 58)\n",
      "First row of transformed data:\n",
      "[ 1.46520197  0.12578387 -0.02556149 -0.3423035  -1.33415091 -0.15355651\n",
      "  0.95211301  0.80330715  0.          0.          0.          0.\n",
      "  0.          0.          1.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          1.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Define raw URLs for train, test, and prod datasets.\n",
    "# -------------------------------\n",
    "train_url = \"https://raw.githubusercontent.com/Jupudy-Nagendra/MLOPS/main/Dataset/Parquet/Metro_Interstate_Traffic_Volume_train.parquet\"\n",
    "test_url  = \"https://raw.githubusercontent.com/Jupudy-Nagendra/MLOPS/main/Dataset/Parquet/Metro_Interstate_Traffic_Volume_test.parquet\"\n",
    "prod_url  = \"https://raw.githubusercontent.com/Jupudy-Nagendra/MLOPS/main/Dataset/Parquet/Metro_Interstate_Traffic_Volume_prod.parquet\"\n",
    "\n",
    "# Helper function to load a parquet file from GitHub.\n",
    "def load_parquet_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return pd.read_parquet(BytesIO(response.content))\n",
    "\n",
    "# Load the train dataset (for example).\n",
    "train_df = load_parquet_from_url(train_url)\n",
    "test_df  = load_parquet_from_url(test_url)\n",
    "prod_df  = load_parquet_from_url(prod_url)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Define a custom transformer to extract datetime features\n",
    "# -------------------------------\n",
    "class DateTimeExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that converts the 'date_time' column into datetime format\n",
    "    and extracts new columns: year, month, day, and hour.\n",
    "    Optionally drops the original date_time column.\n",
    "    \"\"\"\n",
    "    def __init__(self, column=\"date_time\", drop_original=True):\n",
    "        self.column = column\n",
    "        self.drop_original = drop_original\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Convert the column to datetime\n",
    "        X[self.column] = pd.to_datetime(X[self.column])\n",
    "        # Extract datetime components\n",
    "        X['year'] = X[self.column].dt.year\n",
    "        X['month'] = X[self.column].dt.month\n",
    "        X['day'] = X[self.column].dt.day\n",
    "        X['hour'] = X[self.column].dt.hour\n",
    "        # Optionally drop the original date_time column\n",
    "        if self.drop_original:\n",
    "            X = X.drop(columns=[self.column])\n",
    "        return X\n",
    "\n",
    "# Build the datetime extraction pipeline.\n",
    "datetime_pipeline = Pipeline(steps=[\n",
    "    ('datetime_extractor', DateTimeExtractor(column=\"date_time\", drop_original=True))\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Define a custom holiday transformer\n",
    "# -------------------------------\n",
    "class HolidayBinaryTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that converts the 'holiday' column into a binary feature:\n",
    "      - 0 if the value is missing or equals \"None\"\n",
    "      - 1 otherwise.\n",
    "    Implements get_feature_names_out for compatibility.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Expect X as a DataFrame with column 'holiday'\n",
    "        binary = ((~pd.isnull(X)) & (X != \"None\")).astype(int)\n",
    "        # Ensure a 2D array output\n",
    "        if isinstance(binary, pd.Series):\n",
    "            binary = binary.to_frame()\n",
    "        return binary.values\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(['holiday_binary'])\n",
    "\n",
    "# Instantiate our custom holiday transformer.\n",
    "holiday_transformer = HolidayBinaryTransformer()\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Define pipelines for numeric and categorical features\n",
    "# -------------------------------\n",
    "# After datetime extraction, the DataFrame will include:\n",
    "# Numeric columns: 'temp', 'rain_1h', 'snow_1h', 'clouds_all', 'year', 'month', 'day', 'hour'\n",
    "# Categorical columns (excluding 'holiday'): 'weather_main', 'weather_description'\n",
    "numeric_cols = ['temp', 'rain_1h', 'snow_1h', 'clouds_all', 'year', 'month', 'day', 'hour']\n",
    "categorical_cols = ['weather_main', 'weather_description']\n",
    "\n",
    "# Numeric pipeline: impute missing values and scale.\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline: impute missing values and one-hot encode.\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# Step 5: Create a ColumnTransformer to combine all preprocessing steps\n",
    "# -------------------------------\n",
    "# The preprocessor applies:\n",
    "# - Numeric processing on numeric_cols.\n",
    "# - Categorical processing on categorical_cols.\n",
    "# - The holiday transformer on the 'holiday' column.\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_pipeline, numeric_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols),\n",
    "    ('holiday', holiday_transformer, ['holiday'])\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# Step 6: Build the full pipeline\n",
    "# -------------------------------\n",
    "# Chain datetime extraction and the preprocessor.\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('datetime', datetime_pipeline),   # Extract datetime features\n",
    "    ('preprocessor', preprocessor)       # Process numeric, categorical, and holiday columns\n",
    "    # A model step can be added here, e.g., ('model', SomeRegressor())\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# Step 7: Prepare feature data and transform\n",
    "# -------------------------------\n",
    "# Remove the target variable ('traffic_volume') from the train dataset.\n",
    "X_train_features = train_df.drop(columns=['traffic_volume'])\n",
    "\n",
    "# Fit and transform the features using the full pipeline.\n",
    "X_transformed = full_pipeline.fit_transform(X_train_features)\n",
    "\n",
    "# If OneHotEncoder returns a sparse matrix, convert it to a dense array.\n",
    "X_transformed_dense = X_transformed if isinstance(X_transformed, np.ndarray) else X_transformed.toarray()\n",
    "\n",
    "# -------------------------------\n",
    "# Step 8: Retrieve Output Feature Names\n",
    "# -------------------------------\n",
    "# Attempt to get feature names from the preprocessor step.\n",
    "try:\n",
    "    feature_names = full_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "    print(\"Output Feature Names:\")\n",
    "    print(feature_names)\n",
    "except Exception as e:\n",
    "    print(\"Error retrieving feature names:\", e)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 9: Inspect Transformed Data\n",
    "# -------------------------------\n",
    "print(\"\\nTransformed data shape:\", X_transformed_dense.shape)\n",
    "print(\"First row of transformed data:\")\n",
    "print(X_transformed_dense[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee4def20-6cd9-4e21-950f-efebda3103cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "472390d2-e5a6-4652-b101-8c4b63c8634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAPE: 107.65%\n",
      "Production predictions (first 5):\n",
      "[4740.4897   439.21417  685.2893   568.4065  4834.418  ]\n"
     ]
    }
   ],
   "source": [
    "target_col = 'traffic_volume'\n",
    "\n",
    "# For train data\n",
    "X_train = train_df.drop(columns=[target_col])\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "# For test data\n",
    "X_test = test_df.drop(columns=[target_col])\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "# For production data (no target provided, for inference)\n",
    "X_prod = prod_df.copy()\n",
    "\n",
    "# ---------------------------------------\n",
    "# 4. Transform features using the full pipeline\n",
    "# ---------------------------------------\n",
    "X_train_transformed = full_pipeline.fit_transform(X_train)\n",
    "X_test_transformed  = full_pipeline.transform(X_test)\n",
    "X_prod_transformed  = full_pipeline.transform(X_prod)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 5. Train an XGBoost Regressor\n",
    "# ---------------------------------------\n",
    "# Create and train an XGBoost regressor on the preprocessed train data.\n",
    "model = xgb.XGBRegressor(n_estimators=1000, learning_rate=0.01, random_state=42)\n",
    "model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 6. Evaluate the Model on Test Data\n",
    "# ---------------------------------------\n",
    "y_pred_test = model.predict(X_test_transformed)\n",
    "mape_test = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "print(\"Test MAPE: {:.2%}\".format(mape_test))\n",
    "\n",
    "# ---------------------------------------\n",
    "# 7. Predict on Production Data\n",
    "# ---------------------------------------\n",
    "prod_predictions = model.predict(X_prod_transformed)\n",
    "print(\"Production predictions (first 5):\")\n",
    "print(prod_predictions[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff3c5e98-332e-4de2-9037-9b2cd5cc3e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;datetime&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;datetime_extractor&#x27;, DateTimeExtractor())])),\n",
       "                (&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;temp&#x27;, &#x27;rain_1h&#x27;, &#x27;snow_1h&#x27;,\n",
       "                                                   &#x27;clouds_all&#x27;, &#x27;year&#x27;,\n",
       "                                                   &#x27;month&#x27;, &#x27;day&#x27;, &#x27;hour&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImp...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.01,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=None, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, multi_strategy=None,\n",
       "                              n_estimators=1000, n_jobs=None,\n",
       "                              num_parallel_tree=None, random_state=42, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;datetime&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;datetime_extractor&#x27;, DateTimeExtractor())])),\n",
       "                (&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;temp&#x27;, &#x27;rain_1h&#x27;, &#x27;snow_1h&#x27;,\n",
       "                                                   &#x27;clouds_all&#x27;, &#x27;year&#x27;,\n",
       "                                                   &#x27;month&#x27;, &#x27;day&#x27;, &#x27;hour&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImp...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.01,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=None, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, multi_strategy=None,\n",
       "                              n_estimators=1000, n_jobs=None,\n",
       "                              num_parallel_tree=None, random_state=42, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>datetime: Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for datetime: Pipeline</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;datetime_extractor&#x27;, DateTimeExtractor())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DateTimeExtractor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>DateTimeExtractor()</pre></div> </div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessor: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;temp&#x27;, &#x27;rain_1h&#x27;, &#x27;snow_1h&#x27;, &#x27;clouds_all&#x27;,\n",
       "                                  &#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;, &#x27;hour&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;weather_main&#x27;, &#x27;weather_description&#x27;]),\n",
       "                                (&#x27;holiday&#x27;, HolidayBinaryTransformer(),\n",
       "                                 [&#x27;holiday&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;temp&#x27;, &#x27;rain_1h&#x27;, &#x27;snow_1h&#x27;, &#x27;clouds_all&#x27;, &#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;, &#x27;hour&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;weather_main&#x27;, &#x27;weather_description&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>holiday</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;holiday&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>HolidayBinaryTransformer</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>HolidayBinaryTransformer()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('datetime',\n",
       "                 Pipeline(steps=[('datetime_extractor', DateTimeExtractor())])),\n",
       "                ('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['temp', 'rain_1h', 'snow_1h',\n",
       "                                                   'clouds_all', 'year',\n",
       "                                                   'month', 'day', 'hour']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImp...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.01,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=None, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, multi_strategy=None,\n",
       "                              n_estimators=1000, n_jobs=None,\n",
       "                              num_parallel_tree=None, random_state=42, ...))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create the full pipeline by combining the preprocessor and the XGBoost regressor\n",
    "xgb_pipeline = Pipeline(steps=[('datetime', datetime_pipeline),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor(n_estimators=1000, learning_rate=0.01, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data (X_train are the features and y_train is the target)\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "810305ae-9b1d-4f15-880a-3d03f2eb5197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Metrics on Test Data:\n",
      "Mean Absolute Error (MAE): 588.20\n",
      "Mean Squared Error (MSE): 766041.31\n",
      "Root Mean Squared Error (RMSE): 875.24\n",
      "Mean Absolute Percentage Error (MAPE): 107.65%\n",
      "R² Score: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Compute error metrics.\n",
    "mae   = mean_absolute_error(y_test, y_pred_test)\n",
    "mse   = mean_squared_error(y_test, y_pred_test)\n",
    "rmse  = np.sqrt(mse)\n",
    "mape  = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "r2    = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Error Metrics on Test Data:\")\n",
    "print(\"Mean Absolute Error (MAE): {:.2f}\".format(mae))\n",
    "print(\"Mean Squared Error (MSE): {:.2f}\".format(mse))\n",
    "print(\"Root Mean Squared Error (RMSE): {:.2f}\".format(rmse))\n",
    "print(\"Mean Absolute Percentage Error (MAPE): {:.2%}\".format(mape))\n",
    "print(\"R² Score: {:.2f}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdeb0dca-d51c-4e96-b5d4-a68219cfe03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-2.21.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting mlflow-skinny==2.21.0 (from mlflow)\n",
      "  Downloading mlflow_skinny-2.21.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from mlflow) (3.1.5)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting markdown<4,>=3.3 (from mlflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from mlflow) (3.9.4)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from mlflow) (2.0.2)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from mlflow) (19.0.1)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from mlflow) (1.6.1)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from mlflow) (1.13.1)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Downloading sqlalchemy-2.0.39-cp39-cp39-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting waitress<4 (from mlflow)\n",
      "  Using cached waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.21.0->mlflow)\n",
      "  Downloading databricks_sdk-0.46.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting fastapi<1 (from mlflow-skinny==2.21.0->mlflow)\n",
      "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\india\\appdata\\roaming\\python\\python39\\site-packages (from mlflow-skinny==2.21.0->mlflow) (7.1.0)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.21.0->mlflow)\n",
      "  Downloading opentelemetry_api-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.21.0->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: packaging<25 in c:\\users\\india\\appdata\\roaming\\python\\python39\\site-packages (from mlflow-skinny==2.21.0->mlflow) (24.0)\n",
      "Collecting protobuf<6,>=3.12.0 (from mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached protobuf-5.29.3-cp39-cp39-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from mlflow-skinny==2.21.0->mlflow) (2.10.6)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from mlflow-skinny==2.21.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from mlflow-skinny==2.21.0->mlflow) (2.32.3)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from mlflow-skinny==2.21.0->mlflow) (4.12.2)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Using cached Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\india\\appdata\\roaming\\python\\python39\\site-packages (from docker<8,>=4.0.0->mlflow) (306)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
      "Collecting Werkzeug>=3.1 (from Flask<4->mlflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting itsdangerous>=2.2 (from Flask<4->mlflow)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.9 (from Flask<4->mlflow)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\india\\appdata\\roaming\\python\\python39\\site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from matplotlib<4->mlflow) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from matplotlib<4->mlflow) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from matplotlib<4->mlflow) (3.2.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from matplotlib<4->mlflow) (6.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from pandas<3->mlflow) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from pandas<3->mlflow) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<3,>=1.4.0->mlflow)\n",
      "  Using cached greenlet-3.1.1-cp39-cp39-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\india\\appdata\\roaming\\python\\python39\\site-packages (from click<9,>=7.0->mlflow-skinny==2.21.0->mlflow) (0.4.6)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.21.0->mlflow)\n",
      "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\india\\appdata\\roaming\\python\\python39\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.21.0->mlflow) (3.18.1)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.52b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.0->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.0->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.0->mlflow) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\india\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.0->mlflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.0->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\india\\anaconda3\\envs\\mlops\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.0->mlflow) (2025.1.31)\n",
      "Collecting h11>=0.8 (from uvicorn<1->mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached wrapt-1.17.2-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting anyio<5,>=3.6.2 (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\india\\appdata\\roaming\\python\\python39\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.0->mlflow) (1.2.0)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading mlflow-2.21.0-py3-none-any.whl (28.2 MB)\n",
      "   ---------------------------------------- 0.0/28.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 3.7/28.2 MB 19.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.6/28.2 MB 17.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.9/28.2 MB 14.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 11.0/28.2 MB 13.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.8/28.2 MB 12.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 14.2/28.2 MB 11.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 15.5/28.2 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 17.0/28.2 MB 10.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 18.9/28.2 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 20.4/28.2 MB 10.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 22.5/28.2 MB 10.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.6/28.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 26.0/28.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.5/28.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.2/28.2 MB 9.3 MB/s eta 0:00:00\n",
      "Downloading mlflow_skinny-2.21.0-py3-none-any.whl (6.1 MB)\n",
      "   ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.6/6.1 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.9/6.1 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.1/6.1 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading sqlalchemy-2.0.39-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 7.4 MB/s eta 0:00:00\n",
      "Using cached waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading databricks_sdk-0.46.0-py3-none-any.whl (677 kB)\n",
      "   ---------------------------------------- 0.0/677.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 677.5/677.5 kB 6.7 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached greenlet-3.1.1-cp39-cp39-win_amd64.whl (298 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_api-1.31.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_sdk-1.31.0-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl (183 kB)\n",
      "Using cached protobuf-5.29.3-cp39-cp39-win_amd64.whl (434 kB)\n",
      "Using cached sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Using cached uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached wrapt-1.17.2-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: wrapt, Werkzeug, waitress, sqlparse, sniffio, smmap, pyasn1, protobuf, Mako, itsdangerous, h11, greenlet, graphql-core, cloudpickle, click, cachetools, blinker, uvicorn, sqlalchemy, rsa, pyasn1-modules, markdown, graphql-relay, gitdb, Flask, docker, deprecated, anyio, starlette, opentelemetry-api, graphene, google-auth, gitpython, alembic, opentelemetry-semantic-conventions, fastapi, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed Flask-3.1.0 Mako-1.3.9 Werkzeug-3.1.3 alembic-1.15.1 anyio-4.8.0 blinker-1.9.0 cachetools-5.5.2 click-8.1.8 cloudpickle-3.1.1 databricks-sdk-0.46.0 deprecated-1.2.18 docker-7.1.0 fastapi-0.115.11 gitdb-4.0.12 gitpython-3.1.44 google-auth-2.38.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.1.1 h11-0.14.0 itsdangerous-2.2.0 markdown-3.7 mlflow-2.21.0 mlflow-skinny-2.21.0 opentelemetry-api-1.31.0 opentelemetry-sdk-1.31.0 opentelemetry-semantic-conventions-0.52b0 protobuf-5.29.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 rsa-4.9 smmap-5.0.2 sniffio-1.3.1 sqlalchemy-2.0.39 sqlparse-0.5.3 starlette-0.46.1 uvicorn-0.34.0 waitress-3.0.2 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "384ffc98-7e28-4923-862c-abab4965524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d295be7-a9cf-46c7-a0e5-7024e1ebf6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\india\\Desktop\\Jio_Institute\\MLOps\\Project\\Nagendra\\MLOPS\\Notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e742776c-c683-4cb1-a791-e0073f920b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\india\\Desktop\\Jio_Institute\\MLOps\\Project\\Nagendra\\MLOPS\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\india\\Desktop\\Jio_Institute\\MLOps\\Project\\Nagendra\\MLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "50895554-2e24-4c3c-af60-94467f65b9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is E054-376B\n",
      "\n",
      " Directory of C:\\Users\\india\\Desktop\\Jio_Institute\\MLOps\\Project\\Nagendra\\MLOPS\n",
      "\n",
      "16-03-2025  21:19    <DIR>          .\n",
      "09-03-2025  18:17    <DIR>          ..\n",
      "03-03-2025  17:27             3,586 .gitignore\n",
      "03-03-2025  17:46    <DIR>          .ipynb_checkpoints\n",
      "03-03-2025  16:38    <DIR>          Dataset\n",
      "16-03-2025  15:52         2,218,975 Metro_Interstate_Traffic_Volume_Profile.html\n",
      "16-03-2025  21:19    <DIR>          mlruns\n",
      "16-03-2025  22:09    <DIR>          Notebooks\n",
      "03-03-2025  17:27                 7 README.md\n",
      "               3 File(s)      2,222,568 bytes\n",
      "               6 Dir(s)  138,483,531,776 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "21dff818-5fac-4404-a4a5-1e4b96d03313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 21:19:28 INFO mlflow.tracking.fluent: Experiment with name 'Metro_Interstate_Traffic_Volume' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/india/Desktop/Jio_Institute/MLOps/Project/Nagendra/MLOPS/mlruns/411352979973315566', creation_time=1742140168359, experiment_id='411352979973315566', last_update_time=1742140168359, lifecycle_stage='active', name='Metro_Interstate_Traffic_Volume', tags={}>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up MLflow experiment (all runs will be grouped under this experiment)\n",
    "mlflow.set_experiment(\"Metro_Interstate_Traffic_Volume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bbd6ce16-a3e9-405f-a5b3-14906b76ae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Tracking URI: file:///C:/Users/india/Desktop/Jio_Institute/MLOps/Project/Nagendra/MLOPS/mlruns\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "print(\"Current Tracking URI:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd03b1ea-1ecd-40a3-b86c-92b2faf68379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a9e6b4fe-93e9-478c-ad53-cec3e66a3496",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_models = {\n",
    "    \"LinearRegression_default\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.1),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=1000, learning_rate=0.01, random_state=42),\n",
    "    \"ElasticNet\": ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=10, random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "04b4e58f-6c2a-4101-aa71-5a5e9c0909ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 21:19:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression_default -> CV MAE: 1614.5052 ± 11.1028, Test MAE: 1667.9481, RMSE: 5039.5124, R2: -5.3741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 21:19:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge -> CV MAE: 1614.4561 ± 11.1174, Test MAE: 1668.1736, RMSE: 5077.6771, R2: -5.4710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 21:19:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso -> CV MAE: 1614.5782 ± 11.1723, Test MAE: 1665.9483, RMSE: 4866.2458, R2: -4.9434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 21:20:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost -> CV MAE: 587.5652 ± 4.1803, Test MAE: 588.1991, RMSE: 875.2379, R2: 0.8077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 21:20:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet -> CV MAE: 1623.3224 ± 11.0556, Test MAE: 1681.7381, RMSE: 5428.4558, R2: -6.3960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 21:20:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree -> CV MAE: 660.1241 ± 9.5400, Test MAE: 614.6719, RMSE: 1114.6020, R2: 0.6882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 21:21:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest -> CV MAE: 571.4289 ± 10.7549, Test MAE: 557.6689, RMSE: 876.9476, R2: 0.8070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 21:22:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting -> CV MAE: 628.0949 ± 3.5558, Test MAE: 631.9079, RMSE: 921.5203, R2: 0.7869\n"
     ]
    }
   ],
   "source": [
    "for model_name, reg_model in regression_models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log the model name as a parameter.\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        \n",
    "        # Create a full pipeline: preprocessing + regressor.\n",
    "        pipeline = Pipeline(steps=[('datetime', datetime_pipeline),\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', reg_model)\n",
    "        ])\n",
    "        # Define 5-fold cross-validation.\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        # Perform 5-fold cross-validation using negative MAE (we will take the absolute value).\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='neg_mean_absolute_error')\n",
    "        mean_cv = np.mean(np.abs(cv_scores))\n",
    "        std_cv = np.std(np.abs(cv_scores))\n",
    "        \n",
    "        # Log cross-validation metrics.\n",
    "        mlflow.log_metric(\"cv_mean_MAE\", mean_cv)\n",
    "        mlflow.log_metric(\"cv_std_MAE\", std_cv)\n",
    "        \n",
    "        # Train the pipeline on the full training data.\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate on the test set.\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        mae  = mean_absolute_error(y_test, y_pred)\n",
    "        mse  = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        r2   = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Log test metrics.\n",
    "        mlflow.log_metric(\"test_MAE\", mae)\n",
    "        mlflow.log_metric(\"test_MSE\", mse)\n",
    "        mlflow.log_metric(\"test_RMSE\", rmse)\n",
    "        mlflow.log_metric(\"test_MAPE\", mape)\n",
    "        mlflow.log_metric(\"test_R2\", r2)\n",
    "        \n",
    "        # Log hyperparameters if applicable.\n",
    "        if model_name.startswith(\"LinearRegression\") or model_name.startswith(\"Ridge\") or model_name.startswith(\"Lasso\") or model_name.startswith(\"ElasticNet\"):\n",
    "            # For these models, log the regularization strength if available.\n",
    "            if hasattr(reg_model, \"alpha\"):\n",
    "                mlflow.log_param(\"alpha\", reg_model.alpha)\n",
    "            if hasattr(reg_model, \"l1_ratio\"):\n",
    "                mlflow.log_param(\"l1_ratio\", reg_model.l1_ratio)\n",
    "        \n",
    "        # Log the trained model pipeline.\n",
    "        mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "        \n",
    "        print(f\"{model_name} -> CV MAE: {mean_cv:.4f} ± {std_cv:.4f}, Test MAE: {mae:.4f}, RMSE: {rmse:.4f}, R2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c04c86-19b6-48e4-9c84-b9c8643ef9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is E054-376B\n",
      "\n",
      " Directory of C:\\Users\\india\\Desktop\\Jio_Institute\\MLOps\\Project\\Nagendra\\MLOPS\\Notebooks\n",
      "\n",
      "17-03-2025  00:23    <DIR>          .\n",
      "16-03-2025  21:19    <DIR>          ..\n",
      "17-03-2025  00:10    <DIR>          .ipynb_checkpoints\n",
      "16-03-2025  22:18    <DIR>          __pycache__\n",
      "17-03-2025  00:23            12,855 Notebook.ipynb\n",
      "17-03-2025  00:09             5,890 Notebook.py\n",
      "16-03-2025  16:21            58,682 Untitled.ipynb\n",
      "16-03-2025  22:14            83,605 Untitled1.ipynb\n",
      "16-03-2025  22:08             3,429 Untitled2.ipynb\n",
      "16-03-2025  22:17             1,382 Untitled2.py\n",
      "16-03-2025  22:40            14,417 Untitled3.ipynb\n",
      "16-03-2025  22:38             3,166 Untitled3.py\n",
      "16-03-2025  22:02                72 Untitled4.ipynb\n",
      "               9 File(s)        183,498 bytes\n",
      "               4 Dir(s)  137,595,740,160 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78d85c5-0524-46b8-8186-36bdf476e7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Untitled1.ipynb to script\n",
      "[NbConvertApp] Writing 13962 bytes to Untitled1.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script Untitled1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378cb758-c872-4bc3-a51c-43eaeea01b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlops)",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
