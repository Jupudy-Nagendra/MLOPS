{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a163f08d-6e0f-4e37-83b0-ea767bd124b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_dir = r'C:\\Users\\india\\Desktop\\Jio_Institute\\MLOps\\Project\\Nagendra\\MLOPS'\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbb1538d-18b9-4444-9cbe-6f02f4fd5142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is E054-376B\n",
      "\n",
      " Directory of C:\\Users\\india\\Desktop\\Jio_Institute\\MLOps\\Project\\Nagendra\\MLOPS\n",
      "\n",
      "17-03-2025  00:43    <DIR>          .\n",
      "09-03-2025  18:17    <DIR>          ..\n",
      "03-03-2025  17:27             3,586 .gitignore\n",
      "03-03-2025  17:46    <DIR>          .ipynb_checkpoints\n",
      "03-03-2025  16:38    <DIR>          Dataset\n",
      "17-03-2025  00:42         2,218,971 Metro_Interstate_Traffic_Volume_Profile.html\n",
      "17-03-2025  01:07    <DIR>          mlruns\n",
      "17-03-2025  02:06    <DIR>          Notebooks\n",
      "03-03-2025  17:27                 7 README.md\n",
      "               3 File(s)      2,222,564 bytes\n",
      "               6 Dir(s)  134,890,029,056 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe12db-a16c-4457-8e51-c7f325b459be",
   "metadata": {},
   "source": [
    "## Model Monitoring and Data Drift Analysis\n",
    "In this section, we assess whether the production data has significantly drifted from the training data using the alibi-detect library. Specifically, we focus on numeric features such as temperature, rainfall, snowfall, and cloud coverage. The analysis computes key metrics that indicate drift, including:\n",
    "\n",
    "Drift Detected: A flag indicating if drift is present.\n",
    "P-Value: The statistical significance of the drift test.\n",
    "Distance: A measure of the difference between the feature distributions in training and production data.\n",
    "By comparing these metrics, we can determine if the production data’s distribution has changed relative to the training set—information that is critical for monitoring model performance over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca8d3e44-8b2b-4277-a982-d5d9b8d97999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Drift Detection Results:\n",
      "           Metric                                                 Value\n",
      "0  Drift Detected                                                     1\n",
      "1         P-Value           [7.4e-44, 0.00014044569, 1.0, 3.451241e-34]\n",
      "2        Distance  [0.083073415, 0.025691379, 0.0021782727, 0.07325293]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from alibi_detect.cd import TabularDrift\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def detect_numeric_drift(train_file: str, prod_file: str, numeric_features: list, p_value_threshold: float = 0.05) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detects data drift between training and production datasets for numeric features using Alibi Detect's TabularDrift.\n",
    "    \n",
    "    Parameters:\n",
    "        train_file (str): File path to the training dataset (Parquet format).\n",
    "        prod_file (str): File path to the production dataset (Parquet format).\n",
    "        numeric_features (list): List of numeric feature column names to be analyzed.\n",
    "        p_value_threshold (float): Significance threshold for drift detection (default is 0.05).\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame summarizing drift detection metrics including:\n",
    "                      - 'Drift Detected': Flag indicating if drift is detected (True/False)\n",
    "                      - 'P-Value': Statistical significance of the drift test for the features\n",
    "                      - 'Distance': A measure of the distance between the distributions\n",
    "    \"\"\"\n",
    "    # Load the training and production datasets from Parquet files.\n",
    "    train_df = pd.read_parquet(train_file)\n",
    "    prod_df = pd.read_parquet(prod_file)\n",
    "    \n",
    "    # Drop the target column 'traffic_volume' to focus on the features.\n",
    "    X_train = train_df.drop(columns=['traffic_volume'])\n",
    "    X_prod = prod_df.drop(columns=['traffic_volume'])\n",
    "    \n",
    "    # Extract the numeric features as numpy arrays.\n",
    "    X_train_numeric = X_train[numeric_features].values\n",
    "    X_prod_numeric = X_prod[numeric_features].values\n",
    "    \n",
    "    # Initialize the TabularDrift detector with the training data as the reference.\n",
    "    cd = TabularDrift(X_train_numeric, p_val=p_value_threshold)\n",
    "    \n",
    "    # Run the drift detector on the production data.\n",
    "    preds = cd.predict(X_prod_numeric)\n",
    "    \n",
    "    # Extract drift detection results.\n",
    "    drift_detected = preds['data']['is_drift']\n",
    "    p_value = preds['data']['p_val']\n",
    "    distance = preds['data']['distance']\n",
    "    \n",
    "    # Organize the metrics into a DataFrame.\n",
    "    results = pd.DataFrame({\n",
    "        'Metric': ['Drift Detected', 'P-Value', 'Distance'],\n",
    "        'Value': [drift_detected, p_value, distance]\n",
    "    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Define the list of numeric features as per your dataset.\n",
    "numeric_features = [\"temp\", \"rain_1h\", \"snow_1h\", \"clouds_all\"]\n",
    "\n",
    "# Example call:\n",
    "numeric_results = detect_numeric_drift(\n",
    "    train_file='Dataset/Parquet/Metro_Interstate_Traffic_Volume_train.parquet',\n",
    "    prod_file='Dataset/Parquet/Metro_Interstate_Traffic_Volume_prod.parquet',\n",
    "    numeric_features=numeric_features\n",
    ")\n",
    "\n",
    "print(\"Numeric Drift Detection Results:\")\n",
    "print(numeric_results.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1efc0-4a06-43f0-a037-e086fffdb8c1",
   "metadata": {},
   "source": [
    "The numeric drift analysis indicates an overall shift in data distribution between the training and production datasets (Drift Detected = 1). Specifically:\n",
    "\n",
    "Feature 1:\n",
    "P-value: 7.4e-44\n",
    "Distance: 0.083\n",
    "This feature shows extremely significant drift.  \n",
    "\n",
    "Feature 2:\n",
    "P-value: 0.00014\n",
    "Distance: 0.026\n",
    "Drift is significant here as well.  \n",
    "\n",
    "Feature 3:\n",
    "P-value: 1.0\n",
    "Distance: 0.0022\n",
    "No drift is detected for this feature.  \n",
    "\n",
    "Feature 4:\n",
    "P-value: 3.45e-34\n",
    "Distance: 0.073\n",
    "This feature also exhibits significant drift.  \n",
    "\n",
    "In summary, three out of four numeric features show significant distributional changes in production compared to training, which may impact model performance and indicate a need for model retraining or further data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8c682c0-87d7-4c4a-99c5-5467b0bbc940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Drift Detection Results:\n",
      "            Feature  Chi2 Statistic      p-value  Drift Detected\n",
      "            holiday        7.033957 7.222354e-01               0\n",
      "       weather_main      427.780505 1.141185e-85               1\n",
      "weather_description     1664.129109 0.000000e+00               1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def detect_categorical_drift(train_file: str, prod_file: str, categorical_features: list, alpha: float = 0.05) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detects drift in categorical features using the chi-square test.\n",
    "    \n",
    "    For each categorical feature, this function computes the frequency distributions in both the training \n",
    "    and production datasets, aligns them by their categories, and then applies the chi-square test to determine \n",
    "    if the distributions differ significantly.\n",
    "    \n",
    "    Parameters:\n",
    "        train_file (str): File path to the training dataset (Parquet format).\n",
    "        prod_file (str): File path to the production dataset (Parquet format).\n",
    "        categorical_features (list): List of categorical feature column names to be analyzed.\n",
    "        alpha (float): Significance level for the chi-square test (default is 0.05).\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame summarizing the drift detection results for each feature, including:\n",
    "                      - Feature: Name of the categorical feature.\n",
    "                      - Chi2 Statistic: The chi-square test statistic.\n",
    "                      - p-value: The p-value from the chi-square test.\n",
    "                      - Drift Detected: 1 if drift is detected (p < alpha), otherwise 0.\n",
    "    \"\"\"\n",
    "    # Load the training and production datasets from Parquet files.\n",
    "    train_df = pd.read_parquet(train_file)\n",
    "    prod_df = pd.read_parquet(prod_file)\n",
    "    \n",
    "    # Drop the target column 'traffic_volume' from both datasets.\n",
    "    X_train = train_df.drop(columns=['traffic_volume'])\n",
    "    X_prod = prod_df.drop(columns=['traffic_volume'])\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Iterate over each categorical feature for drift detection.\n",
    "    for col in categorical_features:\n",
    "        # Compute frequency counts for each category in training and production data.\n",
    "        train_counts = X_train[col].value_counts().sort_index()\n",
    "        prod_counts = X_prod[col].value_counts().sort_index()\n",
    "        \n",
    "        # Determine the union of categories present in both datasets.\n",
    "        all_categories = sorted(set(train_counts.index) | set(prod_counts.index))\n",
    "        \n",
    "        # Reindex counts to include all categories (fill missing with 0).\n",
    "        train_counts = train_counts.reindex(all_categories, fill_value=0)\n",
    "        prod_counts = prod_counts.reindex(all_categories, fill_value=0)\n",
    "        \n",
    "        # Create a contingency table with datasets as rows and categories as columns.\n",
    "        contingency_table = pd.DataFrame({\n",
    "            'train': train_counts,\n",
    "            'prod': prod_counts\n",
    "        })\n",
    "        \n",
    "        # Perform chi-square test on the transposed table so that each row represents a dataset.\n",
    "        chi2, p, dof, expected = chi2_contingency(contingency_table.T)\n",
    "        \n",
    "        # Determine drift flag based on the p-value.\n",
    "        drift_flag = 1 if p < alpha else 0\n",
    "        \n",
    "        results.append({\n",
    "            'Feature': col,\n",
    "            'Chi2 Statistic': chi2,\n",
    "            'p-value': p,\n",
    "            'Drift Detected': drift_flag\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Define the list of categorical features as per your dataset.\n",
    "categorical_features = ['holiday', 'weather_main', 'weather_description']\n",
    "\n",
    "# Call the function with your file paths (adjust these paths as needed).\n",
    "categorical_results = detect_categorical_drift(\n",
    "    train_file='Dataset/Parquet/Metro_Interstate_Traffic_Volume_train.parquet',\n",
    "    prod_file='Dataset/Parquet/Metro_Interstate_Traffic_Volume_prod.parquet',\n",
    "    categorical_features=categorical_features\n",
    ")\n",
    "\n",
    "# Print the drift detection results in a tabular format.\n",
    "print(\"Categorical Drift Detection Results:\")\n",
    "print(categorical_results.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471c72e-9c0c-44e3-a31d-1ce4408905d5",
   "metadata": {},
   "source": [
    "Summary of Categorical Drift Detection Results:\n",
    "\n",
    "holiday:  \n",
    "Chi² Statistic: 7.034  \n",
    "p-value: 0.722  \n",
    "Drift Detected: 0  \n",
    "This indicates that the distribution of the \"holiday\" feature in production is statistically similar to that in the training data, and no significant drift was detected.\n",
    "\n",
    "weather_main:  \n",
    "Chi² Statistic: 427.781  \n",
    "p-value: 1.14e-85   \n",
    "Drift Detected: 1  \n",
    "The extremely low p-value shows a highly significant difference between the training and production distributions for \"weather_main,\" signaling that drift has occurred.     \n",
    "\n",
    "weather_description:  \n",
    "Chi² Statistic: 1664.129  \n",
    "p-value: 0.0000  \n",
    "Drift Detected: 1  \n",
    "Similar to \"weather_main,\" the near-zero p-value for \"weather_description\" confirms significant drift in its distribution.  \n",
    "\n",
    "In short, while the \"holiday\" feature remains consistent between training and production, both \"weather_main\" and \"weather_description\" show substantial distributional changes, indicating drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07241cd-9d50-4b09-a4fa-7f1cfa73ea41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlops)",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
